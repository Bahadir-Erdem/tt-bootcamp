{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from typing import Literal, List\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset_address = \"../dataset/interim/past_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_knowledge = pd.read_csv(cleaned_dataset_address, parse_dates=[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"past_knowledge\": past_knowledge,\n",
    "    \"cyclical_feature_names\": {\n",
    "        \"month\": 12,\n",
    "        \"day\": 31,\n",
    "        \"day_of_year\": 365,\n",
    "        \"week_of_year\": 52,\n",
    "        \"quarter\": 4,\n",
    "        # \"season\": 4,\n",
    "        \"is_weekend\": 2,\n",
    "    },\n",
    "    \"lag_size\": 30,\n",
    "    \"window_size\": 30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_dates = DataFrame(past_knowledge[\"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"general_dam_occupancy_rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        past_knowledge: DataFrame,\n",
    "        cyclical_feature_names: List[str],\n",
    "        lag_size: int = 30,\n",
    "        window_size: int = 30,\n",
    "    ):\n",
    "        self.PAST_KNOWLEDGE = past_knowledge.sort_values(by=\"datetime\")\n",
    "        self.cyclical_feature_names = cyclical_feature_names\n",
    "        self.lag_size = lag_size\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def transform(self, df: DataFrame) -> DataFrame:\n",
    "        return (\n",
    "            df.sort_values(\"datetime\")\n",
    "            .pipe(self._add_lag_features)\n",
    "            .pipe(self._add_rolling_window_features)\n",
    "            .pipe(self._add_exponential_moving_features)\n",
    "            .pipe(self._drop_columns_with_same_values)\n",
    "            .pipe(self._expand_datetime)\n",
    "            .pipe(self._add_fourier_features)\n",
    "            .pipe(\n",
    "                lambda df: df.astype(\n",
    "                    {col: \"float32\" for col in df.select_dtypes(\"number\").columns}\n",
    "                )\n",
    "            )\n",
    "            .bfill()\n",
    "        )\n",
    "\n",
    "    def _add_lag_features(\n",
    "        self,\n",
    "        df: DataFrame,\n",
    "        fillna_with: Literal[\"ffill\", \"bfill\"] | None = \"bfill\",\n",
    "    ) -> DataFrame:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "        df = df.sort_values(\"datetime\")\n",
    "\n",
    "        full_date_range = pd.date_range(\n",
    "            start=self.PAST_KNOWLEDGE[\"datetime\"].min(),\n",
    "            end=df[\"datetime\"].max(),\n",
    "            freq=\"D\",\n",
    "        )\n",
    "        full_df = pd.DataFrame({\"datetime\": full_date_range})\n",
    "        full_df = full_df.merge(self.PAST_KNOWLEDGE, on=\"datetime\", how=\"left\")\n",
    "\n",
    "        columns_to_use = self.PAST_KNOWLEDGE.select_dtypes(\n",
    "            include=\"number\"\n",
    "        ).columns.tolist()\n",
    "\n",
    "        created_features = []\n",
    "        for col in columns_to_use:\n",
    "            for i in range(1, self.lag_size + 1):\n",
    "                created_col_name = f\"{col}_lag_{i}\"\n",
    "                created_features.append(full_df[col].shift(i).rename(created_col_name))\n",
    "\n",
    "        lags_df = pd.concat([full_df[\"datetime\"], *created_features], axis=1)\n",
    "\n",
    "        df = df.merge(\n",
    "            lags_df,\n",
    "            on=\"datetime\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        if fillna_with == \"ffill\":\n",
    "            df = df.ffill()\n",
    "        elif fillna_with == \"bfill\":\n",
    "            df = df.bfill()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _add_rolling_window_features(\n",
    "        self,\n",
    "        df: DataFrame,\n",
    "        fillna_with: Literal[\"ffill\", \"bfill\"] | None = \"ffill\",\n",
    "    ) -> DataFrame:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "        df = df.sort_values(\"datetime\")\n",
    "\n",
    "        full_date_range = pd.date_range(\n",
    "            start=self.PAST_KNOWLEDGE[\"datetime\"].min(),\n",
    "            end=df[\"datetime\"].max(),\n",
    "            freq=\"D\",\n",
    "        )\n",
    "        full_df = pd.DataFrame({\"datetime\": full_date_range}).merge(\n",
    "            self.PAST_KNOWLEDGE, on=\"datetime\", how=\"left\"\n",
    "        )\n",
    "\n",
    "        columns_to_use = self.PAST_KNOWLEDGE.select_dtypes(\n",
    "            include=[\"number\"]\n",
    "        ).columns.tolist()\n",
    "\n",
    "        metrics = [\"mean\", \"std\", \"min\", \"max\", \"median\", \"var\"]\n",
    "\n",
    "        created_features = []\n",
    "        for col in columns_to_use:\n",
    "            for size in range(2, self.window_size + 1):\n",
    "                rolling_window_feature = (\n",
    "                    full_df[col]\n",
    "                    .rolling(window=size, min_periods=1)\n",
    "                    .agg(metrics)\n",
    "                    .rename(columns=lambda metric: f\"{col}_rw{size}_{metric}\")\n",
    "                )\n",
    "                created_features.append(rolling_window_feature)\n",
    "\n",
    "        window_df = pd.concat([full_df[\"datetime\"], *created_features], axis=1)\n",
    "\n",
    "        df = df.merge(\n",
    "            window_df,\n",
    "            on=\"datetime\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        if fillna_with == \"ffill\":\n",
    "            df = df.ffill()\n",
    "        elif fillna_with == \"bfill\":\n",
    "            df = df.bfill()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _drop_columns_with_same_values(self, df: DataFrame, threshold=0.9) -> DataFrame:\n",
    "        to_drop = [\n",
    "            col\n",
    "            for col in df.columns\n",
    "            if df[col].value_counts(normalize=True, dropna=False).values[0] >= threshold\n",
    "        ]\n",
    "        return df.drop(columns=to_drop)\n",
    "\n",
    "    def _add_exponential_moving_features(\n",
    "        self, df: pd.DataFrame, up_to: int = 30\n",
    "    ) -> pd.DataFrame:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "        df = df.sort_values(\"datetime\")\n",
    "\n",
    "        full_date_range = pd.date_range(\n",
    "            start=self.PAST_KNOWLEDGE[\"datetime\"].min(),\n",
    "            end=df[\"datetime\"].max(),\n",
    "            freq=\"D\",\n",
    "        )\n",
    "        full_df = pd.DataFrame({\"datetime\": full_date_range}).merge(\n",
    "            self.PAST_KNOWLEDGE, on=\"datetime\", how=\"left\"\n",
    "        )\n",
    "\n",
    "        columns_to_use = self.PAST_KNOWLEDGE.select_dtypes(\n",
    "            include=[\"number\"]\n",
    "        ).columns.tolist()\n",
    "\n",
    "        columns_to_use = self.PAST_KNOWLEDGE.select_dtypes(include=\"number\").columns\n",
    "        metrics = [\"mean\"]\n",
    "        created_features = []\n",
    "\n",
    "        for col in columns_to_use:\n",
    "            for span in range(2, up_to + 1):\n",
    "                feature = (\n",
    "                    full_df[col]\n",
    "                    .ewm(span=span, adjust=False)\n",
    "                    .agg(metrics)\n",
    "                    .rename(columns=lambda metric: f\"{col}_em_{span}_{metric}\")\n",
    "                )\n",
    "                created_features.append(feature)\n",
    "\n",
    "        pd.concat([df, *created_features], axis=1)\n",
    "\n",
    "        exponential_moving_df = pd.concat(\n",
    "            [full_df[\"datetime\"], *created_features], axis=1\n",
    "        )\n",
    "\n",
    "        df = df.merge(\n",
    "            exponential_moving_df,\n",
    "            on=\"datetime\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    def _expand_datetime(self, df: DataFrame, column: str = \"datetime\") -> DataFrame:\n",
    "        return df.assign(\n",
    "            **{\n",
    "                \"year\": lambda a_df: a_df[column].dt.year,\n",
    "                \"month\": lambda a_df: a_df[column].dt.month,\n",
    "                \"day\": lambda a_df: a_df[column].dt.day,\n",
    "                \"hour\": lambda a_df: a_df[column].dt.hour,\n",
    "                \"day_of_year\": lambda a_df: a_df[column].dt.dayofyear,\n",
    "                \"week_of_year\": lambda a_df: a_df[column].dt.isocalendar().week,\n",
    "                \"quarter\": lambda a_df: a_df[column].dt.quarter,\n",
    "                # \"season\": lambda a_df: a_df[column].dt.month % 12 // 3 + 1,\n",
    "                \"is_weekend\": lambda a_df: (a_df[column].dt.weekday >= 5).map(\n",
    "                    {True: 1, False: 0}\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _add_fourier_features(self, df: pd.DataFrame, num_terms: int = 7) -> DataFrame:\n",
    "        for col, max_val in self.cyclical_feature_names.items():\n",
    "            source = self._get_column_source(df, col)\n",
    "\n",
    "            for i in range(1, num_terms + 1):\n",
    "                operation = 2 * np.pi * i * source[col] / max_val\n",
    "\n",
    "                df[f\"fourier_sin_{col}_{i}\"] = np.sin(operation)\n",
    "                df[f\"fourier_cos_{col}_{i}\"] = np.cos(operation)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _get_column_source(self, df: DataFrame, col: str) -> List[str]:\n",
    "        if col in df.columns:\n",
    "            source = df\n",
    "        elif col in self.PAST_KNOWLEDGE.columns:\n",
    "            source = self.PAST_KNOWLEDGE\n",
    "        else:\n",
    "            raise KeyError(f\"{col} not found both in df and past knowledge.\")\n",
    "        return source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values = known_dates.merge(past_knowledge, on=\"datetime\", how=\"left\").loc[:, [\"datetime\", TARGET]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_values = feature_extractor.transform(known_dates).loc[:, [\"datetime\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X_values) * 0.7)\n",
    "val_size = int(len(X_values) * 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X_values.iloc[:train_size].merge(y_values, on=\"datetime\", how=\"inner\")\n",
    "\n",
    "val_df = X_values.iloc[train_size : train_size + val_size].merge(\n",
    "    y_values, on=\"datetime\", how=\"inner\"\n",
    ")\n",
    "\n",
    "test_df = X_values.iloc[train_size + val_size :].merge(\n",
    "    y_values, on=\"datetime\", how=\"inner\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = (\n",
    "    train_df.drop(columns=[\"datetime\", \"general_dam_occupancy_rate\"]),\n",
    "    train_df[\"general_dam_occupancy_rate\"],\n",
    ")\n",
    "\n",
    "X_val, y_val = (\n",
    "    val_df.drop(columns=[\"datetime\", \"general_dam_occupancy_rate\"]),\n",
    "    val_df[\"general_dam_occupancy_rate\"],\n",
    ")\n",
    "\n",
    "X_test, y_test = (\n",
    "    test_df.drop(columns=[\"datetime\", \"general_dam_occupancy_rate\"]),\n",
    "    test_df[\"general_dam_occupancy_rate\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_forecaster(y):\n",
    "    return np.full(len(y), y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.46453160118681"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, dummy_forecaster(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.062895669528846"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_val, dummy_forecaster(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.998338269300987"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, dummy_forecaster(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
